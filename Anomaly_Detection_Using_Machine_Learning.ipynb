{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anomaly Detection Using Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuW4en8LbcLApwhgVBymru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AVI18794/Machine-Learning/blob/main/Anomaly_Detection_Using_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsSGyEa0gYEt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL1KKnfUggtt"
      },
      "source": [
        "### The presence of outliers in the dataset can result in the poor fit and lower predictive power of the model.\n",
        "### Identifying and removing the outliers from the dataset is a tedious and challenging task with simple stats for majority of ML algorithms with large number of input variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV0t98ojibMC"
      },
      "source": [
        "### Outliers:- Outliers are observations in the dataset that doesn't fit in some way.The most common or familiar type of outlier is the observations that are far from the rest of the observations or the center of mass of observations.\n",
        "\n",
        "### It can be important to identify and remove outliers from data when training machine learning algorithms for predictive modelling.\n",
        "### Outliers can skew statistical measures and data distributions,providing a misleading representation of the underlying data and relationships.\n",
        "### Removing outliers from training data before modeling can result in a better fit of the data and in turn more skillful predictions.\n",
        "### There are various types of automatic model-based methods for identifying outliers in the input data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2qlNlk3iK6o"
      },
      "source": [
        "#Load and summarize the dataset\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "#load the dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "df = pd.read_csv(url, header=None)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md87B9Z6lkjv"
      },
      "source": [
        "data = df.values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsUfi_XmkwFK"
      },
      "source": [
        "#Split the data into inputs and outputs\n",
        "X,y = data[:,:-1],data[:,-1]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kEqDENfk5V_",
        "outputId": "ea53ea73-7002-45c7-a555-04c47386fd85"
      },
      "source": [
        "#Print the shape of the data\n",
        "X.shape,y.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((506, 13), (506,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTqnq8gxlwwS",
        "outputId": "74c69d19-ebb3-41bf-c82a-9287cb9b2790"
      },
      "source": [
        "#Split the dataset into train and test\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=1)\n",
        "#Check the shape of the train and test sets\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(379, 13) (127, 13) (379,) (127,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRzK_Q33mKXp"
      },
      "source": [
        "#Evaluate the models on the raw dataset\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "model = LinearRegression()\n",
        "model.fit(X_train,y_train)\n",
        "#Evaluate the performance of the model\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apsObRAGmsod",
        "outputId": "32516daf-30e7-42f0-8b9a-d62123453043"
      },
      "source": [
        "#Evaluate the predictions\n",
        "mean_absolute_errorr = mean_absolute_error(y_test,y_pred)\n",
        "print(\"MAE : %.3f\" % mean_absolute_errorr)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE : 3.575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cACQ3Jaom_Uc"
      },
      "source": [
        "#Now try removing the outliers from the datasets\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFccXB3zoJdl"
      },
      "source": [
        "The scikit-learn library provides a number of built-in automatic methods for identifying outliers in the dataset.\n",
        "In this notebook we will compare few of them and compare their performance on the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6OTSlBHo3Gm"
      },
      "source": [
        "### Isolation Forest:- Isolation Forest or iForest is a tree based anomaly detection algorithm.It is based on modeling the normal data in such a way so as to isolate anomalies that are both few in numbers and different in the feature space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m-iimJepfol"
      },
      "source": [
        "### The most important hyperparameter in the model is the “contamination” argument, which is used to help estimate the number of outliers in the dataset. This is a value between 0.0 and 0.5 and by default is set to 0.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gp9ObX6ph90",
        "outputId": "e8fdfc0f-5ec5-4277-ad01-70193f91d34b"
      },
      "source": [
        "#Identifying the outliers in the training dataset\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "y_pred = iso.fit_predict(X_train)\n",
        "#Once the outliers are detected we will remove those outliers from the training set\n",
        "print(\"The outliers are : \",y_pred)\n",
        "#Selecting the rows that are not outliers\n",
        "mask = y_pred!=-1\n",
        "X_train,y_train = X_train[mask,:],y_train[mask]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The outliers are :  [ 1  1  1  1  1  1  1  1  1 -1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1  1  1  1  1 -1  1  1  1 -1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1  1  1 -1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1\n",
            " -1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1  1\n",
            "  1  1  1  1 -1  1  1  1  1  1 -1  1  1  1  1 -1 -1  1  1  1  1  1  1  1\n",
            "  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            " -1  1  1  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1 -1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1 -1  1  1  1  1  1  1  1 -1 -1  1  1  1 -1  1  1  1  1  1  1 -1\n",
            "  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1\n",
            "  1  1  1 -1 -1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1 -1 -1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1  1 -1  1 -1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iea9FZhNqkiN",
        "outputId": "6ce75e39-d910-4352-91ca-95afb8470ecb"
      },
      "source": [
        "#Now build the model after removing the outliers\n",
        "model  = LinearRegression()\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqEPYqjoq3JU",
        "outputId": "71b77e4f-8ba6-4685-a7e3-a7c5bcebfc1b"
      },
      "source": [
        "#Evaluate the model\n",
        "y_pred1 = model.predict(X_test)\n",
        "#Evaluate the predictions\n",
        "mae = mean_absolute_error(y_test,y_pred1)\n",
        "print(\"MAE : %.3f\"%mae)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE : 3.423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua8OHqTErO2E"
      },
      "source": [
        "We can see that in model one when the outliers were not removed from the dataset the prediction was having an error rate MAE of 3.575 and after removing the outliers from the dataset the MAE is 3.423."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQwOG117rt_r"
      },
      "source": [
        "# Minimum Covariance Determinant\n",
        "### If the input variables have a Gaussian distribution, then simple statistical methods can be used to detect outliers.\n",
        "\n",
        "### For example, if the dataset has two input variables and both are Gaussian, then the feature space forms a multi-dimensional Gaussian and knowledge of this distribution can be used to identify values far from the distribution.\n",
        "\n",
        "### This approach can be generalized by defining a hypersphere (ellipsoid) that covers the normal data, and data that falls outside this shape is considered an outlier. An efficient implementation of this technique for multivariate data is known as the Minimum Covariance Determinant, or MCD for short.\n",
        "\n",
        "* The scikit learn provides access to this method via the EllipticEnvelope class\n",
        "* It contains the **contamination** argument that defines the expected ratio of outliers to be observed in practice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YahiluTlrH4g",
        "outputId": "e6cadc21-2f61-4c6b-c426-8ca964de891a"
      },
      "source": [
        "from sklearn.covariance import EllipticEnvelope\n",
        "ee = EllipticEnvelope(contamination=0.01)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# summarize the shape of the training dataset\n",
        "print(X_train.shape, y_train.shape)\n",
        "# identify outliers in the training dataset\n",
        "ee = EllipticEnvelope(contamination=0.01)\n",
        "y_pred2 = ee.fit_predict(X_train)\n",
        "# select all rows that are not outliers\n",
        "mask = y_pred2 != -1\n",
        "X_train, y_train = X_train[mask, :], y_train[mask]\n",
        "# summarize the shape of the updated training dataset\n",
        "print(X_train.shape, y_train.shape)\n",
        "#Fit the model\n",
        "model3 = LinearRegression()\n",
        "model3.fit(X_train,y_train)\n",
        "y_pred2 = model3.predict(X_test)\n",
        "\n",
        "#Evaluate the predictions\n",
        "mae = mean_absolute_error(y_test,y_pred2)\n",
        "print('MAE %.3f'%mae)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(339, 13) (339,)\n",
            "(335, 13) (335,)\n",
            "MAE 3.388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTCRU41zu7kx"
      },
      "source": [
        "## Local Outlier Factor(LOF)\n",
        "### A simplest approach to identifying the outliers is to locate those datapoints that are far from the other datapoints in the feature space.\n",
        "### This approach will work nice for feature space with lower dimensions(fewer features) although it can become less reliable as the number of features is increased, referred to as the curse of dimensionality.\n",
        "\n",
        "### The local outlier factor, or LOF for short, is a technique that attempts to harness the idea of nearest neighbors for outlier detection. Each example is assigned a scoring of how isolated or how likely it is to be outliers based on the size of its local neighborhood. Those examples with the largest score are more likely to be outliers.\n",
        "\n",
        "* <b>The scikit-learn library provides an implementation of this approach in the LocalOutlierFactor class.</b>\n",
        "\n",
        "* <b>The model provides the “contamination” argument, that is the expected percentage of outliers in the dataset, be indicated and defaults to 0.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmpgEr0euuJQ",
        "outputId": "a0b297b5-0c17-43ce-99d5-b399f2e6f9c4"
      },
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# summarize the shape of the training dataset\n",
        "print(X_train.shape, y_train.shape)\n",
        "# identify outliers in the training dataset\n",
        "lof = LocalOutlierFactor()\n",
        "yhat = lof.fit_predict(X_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "X_train, y_train = X_train[mask, :], y_train[mask]\n",
        "# summarize the shape of the updated training dataset\n",
        "print(X_train.shape, y_train.shape)\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(339, 13) (339,)\n",
            "(305, 13) (305,)\n",
            "MAE: 3.356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mc_lo2KwyDX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}